{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMJP/3hqpIX49WBlpkraeDV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anuj-glitch/news_virality/blob/master/news_virality.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRVkPTwwr2pr",
        "colab_type": "text"
      },
      "source": [
        "### ***Crawl news & information websites & anticipate the likelihood of its virality. ***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ2XH-mDXnl_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3b165b4e-2f1e-41f1-956b-f7096e260ea7"
      },
      "source": [
        "#Importing Required Libraries\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Function to scrap headlines from the website www.ndtv.com\n",
        "def webScrapper(pageNo,url,query=''):\n",
        "  data = []\n",
        "  for i in range (pageNo):\n",
        "    if len(query) > 0: \n",
        "      urlFinal = url + str(i) + \"&query=\" + query\n",
        "    else:\n",
        "      urlFinal = url + str(i)\n",
        "    r = requests.get(urlFinal)\n",
        "    soup = BeautifulSoup(r.content, 'html5lib') \n",
        "    table = soup.findAll('p', attrs = {'class':'header fbld'})\n",
        "    for row in table:\n",
        "      data.append(row.get_text())\n",
        "  return data\n",
        "\n",
        "\n",
        "pageNo = 100\n",
        "url = \"https://www.ndtv.com/page/topic-load-more?%20type=news&page=\"\n",
        "headLinesViral  = webScrapper(pageNo,url,'viral') #Viral Headlines\n",
        "headLinesLatest = webScrapper(pageNo,url)         #Not viral, Latest Headlines\n",
        "headLinesTest   = webScrapper(25,url,'india')     #Test Headlines from india\n"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyjuXK9LdJcT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a46ed5e3-0376-442d-eb85-68d8a4576f76"
      },
      "source": [
        "# to remove common news observation in train and test set \n",
        "res=[]\n",
        "for i in headLinesLatest:\n",
        "    if i not in res:\n",
        "      res.append(i)\n",
        "\n",
        "headLinesLatest = res\n",
        "\n",
        "print(len(headLinesViral),len(headLinesLatest),len(headLinesTest))\n",
        "Y =  np.asarray(len(headLinesViral)*[1] + len(headLinesLatest)*[0]) #"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1015 998 375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElGyiTXadMgH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "newsData = pd.DataFrame(headLinesViral + headLinesLatest,columns =['News_Data'])\n",
        "newsData_test = pd.DataFrame(headLinesTest,columns =['News_Data'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwNcH9eMdPj3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sg71zHDdRoh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to remove non-alphanumericals\n",
        "def remove_special_characters(data):\n",
        "  newData = []\n",
        "  for text in data:\n",
        "    pattern = r'[^a-zA-z0-9\\s]'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    newData.append(text)\n",
        "  return newData"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bD5Wt7mfdUJ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lemmatizing\n",
        "def get_lemmatized_text(corpus):\n",
        "    return [' '.join([lemmatizer.lemmatize(word, pos=\"v\") for word in review.split()]) for review in corpus]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNQRYyJDdWb8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b16ea086-54fd-46bb-abb5-5bb2721208a9"
      },
      "source": [
        "def process_data(data):\n",
        "  data_wsc = remove_special_characters(data)\n",
        "  lemm_data = get_lemmatized_text(data_wsc)\n",
        "  return(lemm_data)\n",
        "\n",
        "# Getting processed Data\n",
        "newsData['News_Data'] = process_data(newsData['News_Data'])\n",
        "newsData_test['News_Data']= process_data(newsData_test['News_Data'])\n",
        "\n",
        "newsData.head()"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>News_Data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What Does The Perfect Cup Of Tea Look Like Red...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Internets Dil To Pagal Hai For This Throwback ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>US Official Resigns After Drinking Beer Throwi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Viral A Petition To UninstallWhatsApp For Amit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Viral Video Of Dolphins In Meerut Stuns Intern...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           News_Data\n",
              "0  What Does The Perfect Cup Of Tea Look Like Red...\n",
              "1  Internets Dil To Pagal Hai For This Throwback ...\n",
              "2  US Official Resigns After Drinking Beer Throwi...\n",
              "3  Viral A Petition To UninstallWhatsApp For Amit...\n",
              "4  Viral Video Of Dolphins In Meerut Stuns Intern..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrA8NemwdaJW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ca938a54-ffba-4238-c30c-ee4b92e81bc6"
      },
      "source": [
        "\n",
        "# Function for returning TF - IDF (Term Frequency â€” Inverse Document Frequency) vectoriser the given data\n",
        "\n",
        "def TF_idf(review,review_test):\n",
        "  tfidf_vectorizer = TfidfVectorizer()\n",
        "  tfidf_vectorizer.fit(review)\n",
        "  X = tfidf_vectorizer.transform(review)\n",
        "  X_test = tfidf_vectorizer.transform(review_test)\n",
        "  return(X,X_test)\n",
        "\n",
        "#spiltting the datapoints into train and validation set\n",
        "\n",
        "X,X_test = TF_idf(newsData['News_Data'],newsData_test['News_Data'])\n",
        "X_train,X_val,y_train,y_val = train_test_split(X, Y, train_size=0.7)\n",
        "\n",
        "#Logistic regression model to train the data\n",
        "\n",
        "lr_model = LogisticRegression(C=1)\n",
        "lr_model.fit(X_train,y_train)\n",
        "lr_predict = lr_model.predict(X_val)\n",
        "\n",
        "#Validating the model's accuracy of Logistic Regression\n",
        "\n",
        "print('Validation F1-score : ' + str(f1_score(lr_predict,y_val)))\n",
        "print('Validation Accuracy : ' + str(accuracy_score(lr_predict,y_val)))"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation F1-score : 0.8517241379310344\n",
            "Validation Accuracy : 0.8576158940397351\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmwJOBPGdllt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "3a7772ee-fb94-4efb-ace4-79fb6effec23"
      },
      "source": [
        "lr_model.fit(X,Y)\n",
        "y_test_predict = lr_model.predict_proba(X_test)[:,1]\n",
        "a=[]\n",
        "for b in y_test_predict:\n",
        "    a.append(round(b*100,2)) \n",
        "\n",
        "y_predict_df = pd.DataFrame({'News':headLinesTest,'Virality chances': a })\n",
        "y_predict_df.to_csv('Virality_Predictions.csv')\n",
        "y_predict_df.head()"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>News</th>\n",
              "      <th>Virality chances</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RedmiBook, Mi-Branded Laptops Said to Launch i...</td>\n",
              "      <td>21.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Realme Watch Tipped to Come With 1.4-Inch Disp...</td>\n",
              "      <td>34.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Children In South Asia Could Face Health Crisi...</td>\n",
              "      <td>15.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13,448 Industrial Units Get Permission To Rest...</td>\n",
              "      <td>25.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Uddhav Thackeray, Unelected, Has A Month To Qu...</td>\n",
              "      <td>28.61</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                News  Virality chances\n",
              "0  RedmiBook, Mi-Branded Laptops Said to Launch i...             21.40\n",
              "1  Realme Watch Tipped to Come With 1.4-Inch Disp...             34.87\n",
              "2  Children In South Asia Could Face Health Crisi...             15.83\n",
              "3  13,448 Industrial Units Get Permission To Rest...             25.32\n",
              "4  Uddhav Thackeray, Unelected, Has A Month To Qu...             28.61"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    }
  ]
}